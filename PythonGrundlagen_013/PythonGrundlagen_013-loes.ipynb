{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.02.2025 - Tiefer eintauchen in Textanalyse, plus Spracherkennung \n",
    "---\n",
    "Zunächst schauen wir und die Sentiment Textanalyse, mit der wir letztes mal begonnen haben, genauer an. Welche Idee steckt hinter dem genutzten Modell? Welche anderen Möglichkeiten bietet die transformers Bibliothek? Danach wechseln wir von der Textform unserer Eingabedaten zum Audioformat: Wir erarbeiten, wie online und offline Spracherkennung in Python umgesetzt werden kann.\n",
    "\n",
    "* Zur Bearbeitung der Aufgaben können Sie benötigte Informationen zu Python-Befehlen und zu KI relevanten Bibliotheken (numpy, scikit, pandas) aus allen verfügbaren Quellen beziehen. Die meisten findet man natürlich über eine Suche im Internet, oder durch die Nutzung von KI chat-Systemen selbst.\n",
    "Ein gutes Tutorial für den Start findet sich  z.B. hier: https://www.python-kurs.eu/numerisches_programmieren_in_Python.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase I: Zusatzinformationen zur Textanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die **Sentiment-Analyse** (auch Meinungs- oder Stimmungsanalyse genannt) ist ein wichtiges Werkzeug in der **Textanalyse**. Sie dient dazu, die emotionale Haltung eines Textes automatisch zu bestimmen – ob er **positiv** oder **negativ** ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben bereits mittels **TfidfVectorizer** genutzt, um Textdaten in numerische Werte umzuwandeln, um sie für maschinelles Lernen nutzbar zu machen. Es analysiert die Häufigkeit von Wörtern in einem Text (*Term Frequency*, *TF*) und berücksichtigt, wie wichtig diese Wörter im Vergleich zu anderen Texten sind (*Inverse Document Frequency*, *IDF*).\n",
    "Die resultierenden Ähnlichkeitsvektoren für Texte wurden dann mittels Kosinus-Ähnlichkeit verglichen.\n",
    "\n",
    "Ein \"tieferer\" KI-Ansatz, um die Meinung eines oder mehrerer Texte automatisch zu bestimmen, ist die Sentiment-Analyse basierend auf dem \"BERT\"-Modell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiederholung der Aufgabe: Sentiment-Analyse mit einem vortrainierten BERT-Modell\n",
    "\n",
    "In dieser Aufgabe führen wir eine Sentiment-Analyse auf mehreren deutschen Texten durch, um mittels KI zu analysieren, ob die Texte eine positive oder negative Aussage haben.\n",
    "\n",
    "Installieren Sie zuerst das transformers und das torch Paket: \n",
    "```python\n",
    "pip install transformers torch\n",
    "```\n",
    "\n",
    "Nutze Sie in Ihrem Programm aus der `transformers` Bibliothek die `pipeline` Funktionalität. Sie bietet Zugang zu einem Modell, das auf Sentiment-Analyse spezialisiert ist.\n",
    "Informieren Sie sich, wie ein Modell für deutsche Texte genutzt werden kann.\n",
    "\n",
    "Analysieren Sie die folgenden Textbeispiele:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texts = [\n",
    "    \"Einfach einzurichten, vielseitig nutzbar, starke Leistungsübertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\",\n",
    "    \"Es gibt kaum besseres. Wenn man weiß, wie man ein WLAN-Mesh mit AVM Geräten einrichtet, der sollte hier keine Probleme haben.\",\n",
    "    \"Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Das Produkt ist schlecht\n",
      "Sentiment: negative (Confidence: 0.9958)\n",
      "\n",
      "Text: Einfach einzurichten, vielseitig nutzbar, starke Leistungsübertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\n",
      "Sentiment: positive (Confidence: 0.9995)\n",
      "\n",
      "Text: Es gibt kaum besseres. Wenn man weiß, wie man ein WLAN-Mesh mit AVM Geräten einrichtet, der sollte hier keine Probleme haben.\n",
      "Sentiment: positive (Confidence: 0.9949)\n",
      "\n",
      "Text: Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\n",
      "Sentiment: negative (Confidence: 0.9978)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Von Bibliothek transfomerts das tool pipeline importieren\n",
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment-Analyse-Pipeline mit deutschem Modell laden\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "# Beispieltexte zur Analyse (Deutsch)\n",
    "texts = [\n",
    "    \"Das Produkt ist schlecht\",\n",
    "    \"Einfach einzurichten, vielseitig nutzbar, starke Leistungsübertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\",\n",
    "    \"Es gibt kaum besseres. Wenn man weiß, wie man ein WLAN-Mesh mit AVM Geräten einrichtet, der sollte hier keine Probleme haben.\",\n",
    "    \"Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\"\n",
    "]\n",
    "\n",
    "# Analyse der Texte\n",
    "results = sentiment_pipeline(texts)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "for i in range(len(texts)):\n",
    "    text = texts[i]\n",
    "    result = results[i]\n",
    "    print(f\"Text: {text}\\nSentiment: {result['label']} (Confidence: {result['score']:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusammengefasst:\n",
    "\n",
    "- **NLP (Natural Language Processing)** ist der Bereich der Künstlichen Intelligenz, der sich mit der Verarbeitung von Sprache beschäftigt. Es geht darum, Computern zu ermöglichen, menschliche Sprache zu verstehen, zu interpretieren und darauf zu reagieren.\n",
    "\n",
    "- **BERT (Bidirectional Encoder Representations from Transformers)** ist ein Modell, das für verschiedene NLP-Aufgaben entwickelt wurde. Es versteht den Kontext eines Textes sowohl aus der linken als auch aus der rechten Seite eines Wortes, was zu einer besseren Textverarbeitung führt.\n",
    "\n",
    "- **Transformers** ist eine Python-Bibliothek, die es ermöglicht, BERT und viele andere vortrainierte Modelle für NLP-Aufgaben einfach zu verwenden. Die Bibliothek wurde von Hugging Face entwickelt und bietet eine Vielzahl von Tools zur Bearbeitung von Textdaten.\n",
    "\n",
    "- **Pipeline** ist eine benutzerfreundliche Schnittstelle innerhalb der Transformers-Bibliothek, die vortrainierte Modelle für eine Vielzahl von NLP-Aufgaben (wie Textklassifikation, Named Entity Recognition und Frage-Antwort-Systeme) zur Verfügung stellt. Mit wenigen Zeilen Code kann man so komplexe Aufgaben lösen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die BERT Sentiment Analyse\n",
    "\n",
    "**BERT** ,einschließlich `oliverguhr/german-sentiment-bert`, ist ein Deep Learning-Modell. Es nutzt die eine Architektur mit Selbstaufmerksamkeit, um die Beziehungen zwischen Wörtern und deren Kontext zu erfassen und zu verstehen. Das Modell wurde durch Vortraining und anschließendem Fine-Tuning auf die Sentiment-Analyse angepasst.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Funktionsweise\n",
    "\n",
    "| Punkt                                | Beschreibung                                                                                     |\n",
    "|--------------------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| **1. Vortraining**                   | Das Modell wird auf einem großen Korpus von Textdaten vortrainiert, um Sprachverständnis zu erlangen. |\n",
    "| 1.a. Masked Language Modeling (MLM) | Teilweise maskierte Wörter im Text werden vom Modell vorhergesagt, um den Kontext zu verstehen. Beispiel: \"Der Hund läuft im [MASK].\" |\n",
    "| 1.b. Next Sentence Prediction (NSP)  | Das Modell sagt voraus, ob der zweite Satz sinnvoll auf den ersten folgt. Beispiel: \"Der Hund läuft im Park.\" -> \"Er sieht viele Vögel.\" |\n",
    "| **2. Feinabstimmung**                | Das Modell wird mit gelabelten Daten (positiv, neutral, negativ) trainiert, um Sentiment-Klassen vorherzusagen. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 1. Vortraining:\n",
    "Das Modell wird zuerst auf einem riesigen Korpus von Textdaten (z. B. Wikipedia) vortrainiert, um allgemeines Sprachverständnis zu erlangen. Dabei lernt es, wie Wörter im Kontext miteinander verbunden sind, ohne dass es explizite Labels (wie Sentiment) benötigt.\n",
    "\n",
    "##### 1.a. Masked Language Modeling (MLM):\n",
    "Bei MLM wird ein Teil der Wörter im Text \"maskiert\" (also durch ein spezielles Token ersetzt, z. B. `[MASK]`), und das Modell muss vorhersagen, welches Wort an dieser Stelle steht.\n",
    "\n",
    "Beispiel:\n",
    "- **Originaltext**: \"Der Hund läuft im Park.\"\n",
    "- **Maskierter Text**: \"Der Hund läuft im [MASK].\"\n",
    "- Das Modell muss vorhersagen, dass das fehlende Wort \"Park\" ist.\n",
    "\n",
    "Diese Methode zwingt das Modell, den Kontext auf beiden Seiten eines Wortes zu verstehen, um es richtig zu erraten. So lernt das Modell, die Beziehungen zwischen den Wörtern und deren Bedeutungen zu erkennen, ohne dass es explizite Anweisungen über die Bedeutung der Wörter erhält.\n",
    "\n",
    "##### 1.b. Next Sentence Prediction (NSP):\n",
    "\n",
    "Bei NSP wird das Modell mit zwei Sätzen konfrontiert und muss vorhersagen, ob der zweite Satz inhaltlich auf den ersten folgt oder nicht.\n",
    "\n",
    "Beispiel:\n",
    "- **Satz 1**: „Der Hund läuft im Park.“\n",
    "- **Satz 2**: „Er sieht viele Vögel.“\n",
    "- Die Frage an das Modell wäre: „Folgt Satz 2 sinnvoll auf Satz 1?“ (Ja, in diesem Fall.)\n",
    "\n",
    "Dadurch lernt BERT, Beziehungen zwischen Sätzen zu erkennen und zu verstehen, wie ein Text zusammenhängend strukturiert ist.\n",
    "\n",
    "\n",
    "##### 2. Feinabstimmung:\n",
    "Danach wird das Modell auf spezifische Aufgaben wie Sentiment-Analyse angepasst. Beim Fine-Tuning wird BERT mit gelabelten Daten (positiv, negativ) trainiert, um die richtige Sentiment-Klasse für neue Texte vorherzusagen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Aufgabe: Die BERT-Sentiment-Analyse genauer kennenlernen\n",
    "\n",
    "Wenden Sie die BERT-Sentiment-Analyse aus obiger Aufgabe auf verschiedene, selbstgewählte Texte an. Beobachten Sie die Qualität der automatischen Einstufung in positiv und negativ. \n",
    "\n",
    "Mögliche Fragestellungen:\n",
    "- Ab wann kippt eine Bewertung von positiv nach negativ (oder andersherum).\n",
    "- Mischung positiver und negativer Aussagen in einem Text.\n",
    "- Versuchen Sie auch einmal, die BERT-Sentiment-Analyse \"auszutricksen\", indem Sie komplexe Sätze bilden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Ich arbeite mit dem Router.\n",
      "Sentiment: neutral (Confidence: 0.9998)\n",
      "\n",
      "Text: Das Produkt ist nicht das Gegenteil von nicht schlecht\n",
      "Sentiment: negative (Confidence: 0.9010)\n",
      "\n",
      "Text: Einfach einzurichten, vielseitig nutzbar, starke Leistungsübertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\n",
      "Sentiment: positive (Confidence: 0.9995)\n",
      "\n",
      "Text: Es gibt kaum besseres. Wenn man weiß, wie man ein WLAN-Mesh mit AVM Geräten einrichtet, der sollte hier keine Probleme haben.\n",
      "Sentiment: positive (Confidence: 0.9949)\n",
      "\n",
      "Text: Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\n",
      "Sentiment: negative (Confidence: 0.9978)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Von Bibliothek transfomerts das tool pipeline importieren\n",
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment-Analyse-Pipeline mit deutschem Modell laden (vgl. https://huggingface.co/transformers/v3.0.2/main_classes/pipelines.html)\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "# Beispieltexte zur Analyse (Deutsch)\n",
    "texts = [\n",
    "    \"Ich arbeite mit dem Router.\",\n",
    "    \"Das Produkt ist nicht das Gegenteil von nicht schlecht\",\n",
    "    \"Einfach einzurichten, vielseitig nutzbar, starke Leistungsübertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\",\n",
    "    \"Es gibt kaum besseres. Wenn man weiß, wie man ein WLAN-Mesh mit AVM Geräten einrichtet, der sollte hier keine Probleme haben.\",\n",
    "    \"Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\"\n",
    "]\n",
    "\n",
    "# Analyse der Texte\n",
    "results = sentiment_pipeline(texts)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "for i in range(len(texts)):\n",
    "    text = texts[i]\n",
    "    result = results[i]\n",
    "    print(f\"Text: {text}\\nSentiment: {result['label']} (Confidence: {result['score']:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Aufgabe: Die Transformers Pipeline zur Textvervollständigung\n",
    "\n",
    "Die *transformers* Bibliothek und deren *pipeline* Schnittstelle bietet mehr Features zur Textanalyse als nur die Sentiment Analyse.\n",
    "Eine weitere Möglichkeit ist die *Text-Vervollständigung*. Diese Funktion wird verwendet, um fehlende Wörter in einem Text zu ergänzen.\n",
    "\n",
    "Versuchen Sie zur Lösung der Aufgabe folgendes (zunächst ohne online nach Informationen zu suchen):\n",
    "Ändern Sie das Programm zur Sentiment Analyse von oben so ab, dass die *fill-mask* Funktion benutzt wird. Ein passendes deutschsprachiges Modell ist *dbmdz/bert-base-german-cased*.\n",
    "Das Resultat der pipeline mit der Fill-Mask Funktion ist wieder eine Liste von Dictionaries. Für jeden Textvorschlag ein Dictionary. Jedes Dictionary enthält die Schlüssel \"sequence\" und \"score\". Die Werte hinter diesen Schlüsseln entsprechen der Satzvervollständigung und der zugehörigen Wahrscheinlichkeit.\n",
    "\n",
    "Die Fill-Mask Funktin sagt mit Hilfe des Modells vorher, welches Wort am besten an die Stelle eines Platzhalters [MASK] in einem Text passt. Wenden Sie es an auf den Satz:\n",
    "\n",
    "\"Er [MASK] vom Fahrrad und brach sich den Arm.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at dbmdz/bert-base-german-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorhersage: Er stürzte vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.6612)\n",
      "Vorhersage: Er fiel vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.1385)\n",
      "Vorhersage: Er sprang vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.1028)\n",
      "Vorhersage: Er stieg vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.0371)\n",
      "Vorhersage: Er lief vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.0143)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Pipeline für Masked Language Modeling (fill-mask) mit deutschem BERT laden\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"dbmdz/bert-base-german-cased\")\n",
    "\n",
    "# Beispieltext mit einer Lücke ([MASK])\n",
    "text = \"Er [MASK] vom Fahrrad und brach sich den Arm.\"\n",
    "\n",
    "# Modell ausführen\n",
    "results = fill_mask(text)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "for result in results:\n",
    "    print(f\"Vorhersage: {result['sequence']} (Wahrscheinlichkeit: {result['score']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase II - Spracherkennung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spracherkennung ist eine der zentralen Anwenudngen in der Künstlichen Intelligenz, denn sie ermöglicht es, die natürliche, gesprochene Sprache zu verstehen und zu verarbeiten. Sobald gesprochene Sprache in Text umgewandelt wurde, können alle Technologien zur Textverarbeitung angewandt werden. Spracherkennung bildet die Grundlage für digitale Assistenten wie Siri oder Alexa, Transkriptionssoftware und sprachgesteuerte Steuerungssysteme.  \n",
    "Durch Fortschritte in Deep Learning und neuronalen Netzen hat sich die Genauigkeit der Spracherkennung erheblich verbessert. Moderne Systeme nutzen riesige Sprachmodelle und selbstlernende Algorithmen, um Dialekte, Akzente und sogar Emotionen in der Sprache besser zu erfassen.\n",
    "\n",
    "Dank leistungsstarker Bibliotheken wie SpeechRecognition, whisper und vosk kann man in Python mit wenigen Zeilen Code gesprochene Sprache in Text umwandeln."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aufgabe\n",
    "\n",
    "Wir starten mit einer Spracherkennungsengine von Google.\n",
    "Installieren Sie dazu das Python Paket `SpeechRecognition`.\n",
    "<!-- <span style=\"font-family: monospace; color:white;\"> SpeechRecognition </span>. -->\n",
    "\n",
    "Informieren Sie Sich über das Modul SpeechRecognition und seine Arbeitsweise. \n",
    "Schreiben Sie ein Python Programm, das mit dieser Bibliothek eine Audio-Datei mit deutscher Sprache in Text umwandelt. Der erkannte Text soll ausgegeben werden.\n",
    "Es gibt unterschiedliche ErkennungsModelle (\"recognize\"), die mit dieser Bibliothek benutzt werden können. Benutzen Sie in dieser Aufgabe Googles online (!) Modell. \n",
    "\n",
    "Nehmen Sie eine eigene Audio Datei auf und lassen Sie diese von Ihrem Programm in Text umwandeln.\n",
    "\n",
    "Bevor wir verschiedene Versuche mit unserem Programm machen, lassen Sie uns gemeinsam eine Lösungsvariante anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google konnte den Text nicht verstehen.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Einen Recognizer erstellen\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Die WAV-Datei laden\n",
    "with sr.AudioFile(\"./AudioKatze2.wav\") as source:\n",
    "    audio_data = r.record(source)\n",
    "\n",
    "# Offline-Erkennung mit Googles online Modell durchführen\n",
    "try:\n",
    "    text = r.recognize_google(audio_data, language=\"en-US\")\n",
    "    print(\"Erkannter Text:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google konnte den Text nicht verstehen.\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Fehler bei der Google-Anfrage:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Aufgabe\n",
    "\n",
    "- Testen Sie verschiedene Audioaufnahmen. Wie schlecht muss die Qualität sein, damit Googles online Modell Probleme bei der Erkennung hat?\n",
    "- Testen Sie auch verschiedene Sprachen, soweit möglich :) \n",
    "- Testen Sie eine Kombination aus Audioaufnahme und Spracheinstellung im code, die nicht zusammengehören."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online vs. Lokal\n",
    "\n",
    "Die Nutzung der Google *online* Spracherkennung ist mit Nachteilen verbunden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Aufgabe\n",
    "\n",
    "Mit dem Modul SpeechRecognition kann auch offline Spracherkennung betrieben werden.\n",
    "Installieren Sie dazu das Python Paket `pocketsphinx`. Es enthält das offline SprachModell *für englische Sprache*.\n",
    "Ändern Sie Ihr obiges Programm so ab, dass anstelle des Google online Modells nun das offline Modell *Sphinx* benutzt wird.\n",
    "\n",
    "Analysieren Sie verschiedene Audioaufnahmen/-dateien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erkannter Text: what a beautiful weather\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Einen Recognizer erstellen\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Die WAV-Datei laden\n",
    "with sr.AudioFile(\"./AudioWeather.wav\") as source:\n",
    "    audio_data = r.record(source)\n",
    "\n",
    "# Offline-Erkennung mit Sphinx (pocketsphinx) durchführen\n",
    "try:\n",
    "    text = r.recognize_sphinx(audio_data, language=\"en-US\")\n",
    "    print(\"Erkannter Text:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sphinx konnte den Text nicht verstehen.\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Fehler bei der Sphinx-Anfrage:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
