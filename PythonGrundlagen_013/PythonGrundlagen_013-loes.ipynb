{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.02.2025 - Tiefer eintauchen in Textanalyse, plus Spracherkennung \n",
    "---\n",
    "Zun√§chst schauen wir und die Sentiment Textanalyse, mit der wir letztes mal begonnen haben, genauer an. Welche Idee steckt hinter dem genutzten Modell? Welche anderen M√∂glichkeiten bietet die transformers Bibliothek? Danach wechseln wir von der Textform unserer Eingabedaten zum Audioformat: Wir erarbeiten, wie online und offline Spracherkennung in Python umgesetzt werden kann.\n",
    "\n",
    "* Zur Bearbeitung der Aufgaben k√∂nnen Sie ben√∂tigte Informationen zu Python-Befehlen und zu KI relevanten Bibliotheken (numpy, scikit, pandas) aus allen verf√ºgbaren Quellen beziehen. Die meisten findet man nat√ºrlich √ºber eine Suche im Internet, oder durch die Nutzung von KI chat-Systemen selbst.\n",
    "Ein gutes Tutorial f√ºr den Start findet sich  z.B. hier: https://www.python-kurs.eu/numerisches_programmieren_in_Python.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase I: Zusatzinformationen zur Textanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die **Sentiment-Analyse** (auch Meinungs- oder Stimmungsanalyse genannt) ist ein wichtiges Werkzeug in der **Textanalyse**. Sie dient dazu, die emotionale Haltung eines Textes automatisch zu bestimmen ‚Äì ob er **positiv** oder **negativ** ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben bereits mittels **TfidfVectorizer** genutzt, um Textdaten in numerische Werte umzuwandeln, um sie f√ºr maschinelles Lernen nutzbar zu machen. Es analysiert die H√§ufigkeit von W√∂rtern in einem Text (*Term Frequency*, *TF*) und ber√ºcksichtigt, wie wichtig diese W√∂rter im Vergleich zu anderen Texten sind (*Inverse Document Frequency*, *IDF*).\n",
    "Die resultierenden √Ñhnlichkeitsvektoren f√ºr Texte wurden dann mittels Kosinus-√Ñhnlichkeit verglichen.\n",
    "\n",
    "Ein \"tieferer\" KI-Ansatz, um die Meinung eines oder mehrerer Texte automatisch zu bestimmen, ist die Sentiment-Analyse basierend auf dem \"BERT\"-Modell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiederholung der Aufgabe: Sentiment-Analyse mit einem vortrainierten BERT-Modell\n",
    "\n",
    "In dieser Aufgabe f√ºhren wir eine Sentiment-Analyse auf mehreren deutschen Texten durch, um mittels KI zu analysieren, ob die Texte eine positive oder negative Aussage haben.\n",
    "\n",
    "Installieren Sie zuerst das transformers und das torch Paket: \n",
    "```python\n",
    "pip install transformers torch\n",
    "```\n",
    "\n",
    "Nutze Sie in Ihrem Programm aus der `transformers` Bibliothek die `pipeline` Funktionalit√§t. Sie bietet Zugang zu einem Modell, das auf Sentiment-Analyse spezialisiert ist.\n",
    "Informieren Sie sich, wie ein Modell f√ºr deutsche Texte genutzt werden kann.\n",
    "\n",
    "Analysieren Sie die folgenden Textbeispiele:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texts = [\n",
    "    \"Einfach einzurichten, vielseitig nutzbar, starke Leistungs√ºbertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\",\n",
    "    \"Es gibt kaum besseres. Wenn man wei√ü, wie man ein WLAN-Mesh mit AVM Ger√§ten einrichtet, der sollte hier keine Probleme haben.\",\n",
    "    \"Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Das Produkt ist schlecht\n",
      "Sentiment: negative (Confidence: 0.9958)\n",
      "\n",
      "Text: Einfach einzurichten, vielseitig nutzbar, starke Leistungs√ºbertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\n",
      "Sentiment: positive (Confidence: 0.9995)\n",
      "\n",
      "Text: Es gibt kaum besseres. Wenn man wei√ü, wie man ein WLAN-Mesh mit AVM Ger√§ten einrichtet, der sollte hier keine Probleme haben.\n",
      "Sentiment: positive (Confidence: 0.9949)\n",
      "\n",
      "Text: Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\n",
      "Sentiment: negative (Confidence: 0.9978)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Von Bibliothek transfomerts das tool pipeline importieren\n",
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment-Analyse-Pipeline mit deutschem Modell laden\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "# Beispieltexte zur Analyse (Deutsch)\n",
    "texts = [\n",
    "    \"Das Produkt ist schlecht\",\n",
    "    \"Einfach einzurichten, vielseitig nutzbar, starke Leistungs√ºbertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\",\n",
    "    \"Es gibt kaum besseres. Wenn man wei√ü, wie man ein WLAN-Mesh mit AVM Ger√§ten einrichtet, der sollte hier keine Probleme haben.\",\n",
    "    \"Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\"\n",
    "]\n",
    "\n",
    "# Analyse der Texte\n",
    "results = sentiment_pipeline(texts)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "for i in range(len(texts)):\n",
    "    text = texts[i]\n",
    "    result = results[i]\n",
    "    print(f\"Text: {text}\\nSentiment: {result['label']} (Confidence: {result['score']:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusammengefasst:\n",
    "\n",
    "- **NLP (Natural Language Processing)** ist der Bereich der K√ºnstlichen Intelligenz, der sich mit der Verarbeitung von Sprache besch√§ftigt. Es geht darum, Computern zu erm√∂glichen, menschliche Sprache zu verstehen, zu interpretieren und darauf zu reagieren.\n",
    "\n",
    "- **BERT (Bidirectional Encoder Representations from Transformers)** ist ein Modell, das f√ºr verschiedene NLP-Aufgaben entwickelt wurde. Es versteht den Kontext eines Textes sowohl aus der linken als auch aus der rechten Seite eines Wortes, was zu einer besseren Textverarbeitung f√ºhrt.\n",
    "\n",
    "- **Transformers** ist eine Python-Bibliothek, die es erm√∂glicht, BERT und viele andere vortrainierte Modelle f√ºr NLP-Aufgaben einfach zu verwenden. Die Bibliothek wurde von Hugging Face entwickelt und bietet eine Vielzahl von Tools zur Bearbeitung von Textdaten.\n",
    "\n",
    "- **Pipeline** ist eine benutzerfreundliche Schnittstelle innerhalb der Transformers-Bibliothek, die vortrainierte Modelle f√ºr eine Vielzahl von NLP-Aufgaben (wie Textklassifikation, Named Entity Recognition und Frage-Antwort-Systeme) zur Verf√ºgung stellt. Mit wenigen Zeilen Code kann man so komplexe Aufgaben l√∂sen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die BERT Sentiment Analyse\n",
    "\n",
    "**BERT** ,einschlie√ülich `oliverguhr/german-sentiment-bert`, ist ein Deep Learning-Modell. Es nutzt die eine Architektur mit Selbstaufmerksamkeit, um die Beziehungen zwischen W√∂rtern und deren Kontext zu erfassen und zu verstehen. Das Modell wurde durch Vortraining und anschlie√üendem Fine-Tuning auf die Sentiment-Analyse angepasst.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Funktionsweise\n",
    "\n",
    "| Punkt                                | Beschreibung                                                                                     |\n",
    "|--------------------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| **1. Vortraining**                   | Das Modell wird auf einem gro√üen Korpus von Textdaten vortrainiert, um Sprachverst√§ndnis zu erlangen. |\n",
    "| 1.a. Masked Language Modeling (MLM) | Teilweise maskierte W√∂rter im Text werden vom Modell vorhergesagt, um den Kontext zu verstehen. Beispiel: \"Der Hund l√§uft im [MASK].\" |\n",
    "| 1.b. Next Sentence Prediction (NSP)  | Das Modell sagt voraus, ob der zweite Satz sinnvoll auf den ersten folgt. Beispiel: \"Der Hund l√§uft im Park.\" -> \"Er sieht viele V√∂gel.\" |\n",
    "| **2. Feinabstimmung**                | Das Modell wird mit gelabelten Daten (positiv, neutral, negativ) trainiert, um Sentiment-Klassen vorherzusagen. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 1. Vortraining:\n",
    "Das Modell wird zuerst auf einem riesigen Korpus von Textdaten (z. B. Wikipedia) vortrainiert, um allgemeines Sprachverst√§ndnis zu erlangen. Dabei lernt es, wie W√∂rter im Kontext miteinander verbunden sind, ohne dass es explizite Labels (wie Sentiment) ben√∂tigt.\n",
    "\n",
    "##### 1.a. Masked Language Modeling (MLM):\n",
    "Bei MLM wird ein Teil der W√∂rter im Text \"maskiert\" (also durch ein spezielles Token ersetzt, z. B. `[MASK]`), und das Modell muss vorhersagen, welches Wort an dieser Stelle steht.\n",
    "\n",
    "Beispiel:\n",
    "- **Originaltext**: \"Der Hund l√§uft im Park.\"\n",
    "- **Maskierter Text**: \"Der Hund l√§uft im [MASK].\"\n",
    "- Das Modell muss vorhersagen, dass das fehlende Wort \"Park\" ist.\n",
    "\n",
    "Diese Methode zwingt das Modell, den Kontext auf beiden Seiten eines Wortes zu verstehen, um es richtig zu erraten. So lernt das Modell, die Beziehungen zwischen den W√∂rtern und deren Bedeutungen zu erkennen, ohne dass es explizite Anweisungen √ºber die Bedeutung der W√∂rter erh√§lt.\n",
    "\n",
    "##### 1.b. Next Sentence Prediction (NSP):\n",
    "\n",
    "Bei NSP wird das Modell mit zwei S√§tzen konfrontiert und muss vorhersagen, ob der zweite Satz inhaltlich auf den ersten folgt oder nicht.\n",
    "\n",
    "Beispiel:\n",
    "- **Satz 1**: ‚ÄûDer Hund l√§uft im Park.‚Äú\n",
    "- **Satz 2**: ‚ÄûEr sieht viele V√∂gel.‚Äú\n",
    "- Die Frage an das Modell w√§re: ‚ÄûFolgt Satz 2 sinnvoll auf Satz 1?‚Äú (Ja, in diesem Fall.)\n",
    "\n",
    "Dadurch lernt BERT, Beziehungen zwischen S√§tzen zu erkennen und zu verstehen, wie ein Text zusammenh√§ngend strukturiert ist.\n",
    "\n",
    "\n",
    "##### 2. Feinabstimmung:\n",
    "Danach wird das Modell auf spezifische Aufgaben wie Sentiment-Analyse angepasst. Beim Fine-Tuning wird BERT mit gelabelten Daten (positiv, negativ) trainiert, um die richtige Sentiment-Klasse f√ºr neue Texte vorherzusagen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Aufgabe: Die BERT-Sentiment-Analyse genauer kennenlernen\n",
    "\n",
    "Wenden Sie die BERT-Sentiment-Analyse aus obiger Aufgabe auf verschiedene, selbstgew√§hlte Texte an. Beobachten Sie die Qualit√§t der automatischen Einstufung in positiv und negativ. \n",
    "\n",
    "M√∂gliche Fragestellungen:\n",
    "- Ab wann kippt eine Bewertung von positiv nach negativ (oder andersherum).\n",
    "- Mischung positiver und negativer Aussagen in einem Text.\n",
    "- Versuchen Sie auch einmal, die BERT-Sentiment-Analyse \"auszutricksen\", indem Sie komplexe S√§tze bilden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Ich arbeite mit dem Router.\n",
      "Sentiment: neutral (Confidence: 0.9998)\n",
      "\n",
      "Text: Das Produkt ist nicht das Gegenteil von nicht schlecht\n",
      "Sentiment: negative (Confidence: 0.9010)\n",
      "\n",
      "Text: Einfach einzurichten, vielseitig nutzbar, starke Leistungs√ºbertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\n",
      "Sentiment: positive (Confidence: 0.9995)\n",
      "\n",
      "Text: Es gibt kaum besseres. Wenn man wei√ü, wie man ein WLAN-Mesh mit AVM Ger√§ten einrichtet, der sollte hier keine Probleme haben.\n",
      "Sentiment: positive (Confidence: 0.9949)\n",
      "\n",
      "Text: Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\n",
      "Sentiment: negative (Confidence: 0.9978)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Von Bibliothek transfomerts das tool pipeline importieren\n",
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment-Analyse-Pipeline mit deutschem Modell laden (vgl. https://huggingface.co/transformers/v3.0.2/main_classes/pipelines.html)\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "# Beispieltexte zur Analyse (Deutsch)\n",
    "texts = [\n",
    "    \"Ich arbeite mit dem Router.\",\n",
    "    \"Das Produkt ist nicht das Gegenteil von nicht schlecht\",\n",
    "    \"Einfach einzurichten, vielseitig nutzbar, starke Leistungs√ºbertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\",\n",
    "    \"Es gibt kaum besseres. Wenn man wei√ü, wie man ein WLAN-Mesh mit AVM Ger√§ten einrichtet, der sollte hier keine Probleme haben.\",\n",
    "    \"Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\"\n",
    "]\n",
    "\n",
    "# Analyse der Texte\n",
    "results = sentiment_pipeline(texts)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "for i in range(len(texts)):\n",
    "    text = texts[i]\n",
    "    result = results[i]\n",
    "    print(f\"Text: {text}\\nSentiment: {result['label']} (Confidence: {result['score']:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Aufgabe: Die Transformers Pipeline zur Textvervollst√§ndigung\n",
    "\n",
    "Die *transformers* Bibliothek und deren *pipeline* Schnittstelle bietet mehr Features zur Textanalyse als nur die Sentiment Analyse.\n",
    "Eine weitere M√∂glichkeit ist die *Text-Vervollst√§ndigung*. Diese Funktion wird verwendet, um fehlende W√∂rter in einem Text zu erg√§nzen.\n",
    "\n",
    "Versuchen Sie zur L√∂sung der Aufgabe folgendes (zun√§chst ohne online nach Informationen zu suchen):\n",
    "√Ñndern Sie das Programm zur Sentiment Analyse von oben so ab, dass die *fill-mask* Funktion benutzt wird. Ein passendes deutschsprachiges Modell ist *dbmdz/bert-base-german-cased*.\n",
    "Das Resultat der pipeline mit der Fill-Mask Funktion ist wieder eine Liste von Dictionaries. F√ºr jeden Textvorschlag ein Dictionary. Jedes Dictionary enth√§lt die Schl√ºssel \"sequence\" und \"score\". Die Werte hinter diesen Schl√ºsseln entsprechen der Satzvervollst√§ndigung und der zugeh√∂rigen Wahrscheinlichkeit.\n",
    "\n",
    "Die Fill-Mask Funktin sagt mit Hilfe des Modells vorher, welches Wort am besten an die Stelle eines Platzhalters [MASK] in einem Text passt. Wenden Sie es an auf den Satz:\n",
    "\n",
    "\"Er [MASK] vom Fahrrad und brach sich den Arm.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at dbmdz/bert-base-german-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorhersage: Er st√ºrzte vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.6612)\n",
      "Vorhersage: Er fiel vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.1385)\n",
      "Vorhersage: Er sprang vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.1028)\n",
      "Vorhersage: Er stieg vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.0371)\n",
      "Vorhersage: Er lief vom Fahrrad und brach sich den Arm. (Wahrscheinlichkeit: 0.0143)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Pipeline f√ºr Masked Language Modeling (fill-mask) mit deutschem BERT laden\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"dbmdz/bert-base-german-cased\")\n",
    "\n",
    "# Beispieltext mit einer L√ºcke ([MASK])\n",
    "text = \"Er [MASK] vom Fahrrad und brach sich den Arm.\"\n",
    "\n",
    "# Modell ausf√ºhren\n",
    "results = fill_mask(text)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "for result in results:\n",
    "    print(f\"Vorhersage: {result['sequence']} (Wahrscheinlichkeit: {result['score']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase II - Spracherkennung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spracherkennung ist eine der zentralen Anwenudngen in der K√ºnstlichen Intelligenz, denn sie erm√∂glicht es, die nat√ºrliche, gesprochene Sprache zu verstehen und zu verarbeiten. Sobald gesprochene Sprache in Text umgewandelt wurde, k√∂nnen alle Technologien zur Textverarbeitung angewandt werden. Spracherkennung bildet die Grundlage f√ºr digitale Assistenten wie Siri oder Alexa, Transkriptionssoftware und sprachgesteuerte Steuerungssysteme.  \n",
    "Durch Fortschritte in Deep Learning und neuronalen Netzen hat sich die Genauigkeit der Spracherkennung erheblich verbessert. Moderne Systeme nutzen riesige Sprachmodelle und selbstlernende Algorithmen, um Dialekte, Akzente und sogar Emotionen in der Sprache besser zu erfassen.\n",
    "\n",
    "Dank leistungsstarker Bibliotheken wie SpeechRecognition, whisper und vosk kann man in Python mit wenigen Zeilen Code gesprochene Sprache in Text umwandeln."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aufgabe\n",
    "\n",
    "Wir starten mit einer Spracherkennungsengine von Google.\n",
    "Installieren Sie dazu das Python Paket `SpeechRecognition`.\n",
    "<!-- <span style=\"font-family: monospace; color:white;\"> SpeechRecognition </span>. -->\n",
    "\n",
    "Informieren Sie Sich √ºber das Modul SpeechRecognition und seine Arbeitsweise. \n",
    "Schreiben Sie ein Python Programm, das mit dieser Bibliothek eine Audio-Datei mit deutscher Sprache in Text umwandelt. Der erkannte Text soll ausgegeben werden.\n",
    "Es gibt unterschiedliche ErkennungsModelle (\"recognize\"), die mit dieser Bibliothek benutzt werden k√∂nnen. Benutzen Sie in dieser Aufgabe Googles online (!) Modell. \n",
    "\n",
    "Nehmen Sie eine eigene Audio Datei auf und lassen Sie diese von Ihrem Programm in Text umwandeln.\n",
    "\n",
    "Bevor wir verschiedene Versuche mit unserem Programm machen, lassen Sie uns gemeinsam eine L√∂sungsvariante anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google konnte den Text nicht verstehen.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Einen Recognizer erstellen\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Die WAV-Datei laden\n",
    "with sr.AudioFile(\"./AudioKatze2.wav\") as source:\n",
    "    audio_data = r.record(source)\n",
    "\n",
    "# Offline-Erkennung mit Googles online Modell durchf√ºhren\n",
    "try:\n",
    "    text = r.recognize_google(audio_data, language=\"en-US\")\n",
    "    print(\"Erkannter Text:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google konnte den Text nicht verstehen.\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Fehler bei der Google-Anfrage:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Aufgabe\n",
    "\n",
    "- Testen Sie verschiedene Audioaufnahmen. Wie schlecht muss die Qualit√§t sein, damit Googles online Modell Probleme bei der Erkennung hat?\n",
    "- Testen Sie auch verschiedene Sprachen, soweit m√∂glich :) \n",
    "- Testen Sie eine Kombination aus Audioaufnahme und Spracheinstellung im code, die nicht zusammengeh√∂ren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online vs. Lokal\n",
    "\n",
    "Die Nutzung der Google *online* Spracherkennung ist mit Nachteilen verbunden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Aufgabe\n",
    "\n",
    "Mit dem Modul SpeechRecognition kann auch offline Spracherkennung betrieben werden.\n",
    "Installieren Sie dazu das Python Paket `pocketsphinx`. Es enth√§lt das offline SprachModell *f√ºr englische Sprache*.\n",
    "√Ñndern Sie Ihr obiges Programm so ab, dass anstelle des Google online Modells nun das offline Modell *Sphinx* benutzt wird.\n",
    "\n",
    "Analysieren Sie verschiedene Audioaufnahmen/-dateien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erkannter Text: what a beautiful weather\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Einen Recognizer erstellen\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Die WAV-Datei laden\n",
    "with sr.AudioFile(\"./AudioWeather.wav\") as source:\n",
    "    audio_data = r.record(source)\n",
    "\n",
    "# Offline-Erkennung mit Sphinx (pocketsphinx) durchf√ºhren\n",
    "try:\n",
    "    text = r.recognize_sphinx(audio_data, language=\"en-US\")\n",
    "    print(\"Erkannter Text:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sphinx konnte den Text nicht verstehen.\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Fehler bei der Sphinx-Anfrage:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
