{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04.06.2025 - Entscheidungsbäume - Erweiterungen\n",
    "---\n",
    "Nach einer Wiederholung dazu, wie ein einfaches Python Programm zur Ausführung eines Entscheidungsbaumes aufgebaut ist, betrachten wir genauer den Gini-Index und seine Bedeutung. Danach wenden wir die Entscheidungsbäume auf einen anderen Anwendungsfall an: Die Klassifizierung von Pilzen. Neben dem Anwedungsbezug steht hier die Art der Merkmalswerte im Fokus. Im Anschluss gehen wir auf die Bewertung der Qualität eines trainierten Entscheidungsbaumes ein.\n",
    "\n",
    "* Zur Bearbeitung der Aufgaben können Sie benötigte Informationen zu Python-Befehlen und zu KI relevanten Bibliotheken (numpy, scikit, pandas) aus allen verfügbaren Quellen beziehen. Die meisten findet man natürlich über eine Suche im Internet, oder durch die Nutzung von KI chat-Systemen selbst.\n",
    "Ein gutes Tutorial für den Start findet sich  z.B. hier: https://www.python-kurs.eu/numerisches_programmieren_in_Python.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase I - Wiederholung: Anwendung von Entscheidungsbäumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiederholung der Aufgabe: Klassifikation der Schwertlilien mit einem Entscheidungsbaum\n",
    "\n",
    "<img src=\"./PythonGrundlagen_023_Bilder/iris_flower_magnifying_glass.webp\" alt=\"Diagramm\" width=\"550\" />\n",
    "\n",
    "Schreiben Sie ein Python-Programm, das die berühmten *Schwertlilien-Daten (Iris-Datensatz)* mithilfe eines Entscheidungsbaums klassifiziert.\n",
    "Trainieren Sie dazu ein Entscheidungsbaum-Modell auf dem Iris-Datensatz, um die drei Iris-Arten (Setosa, Versicolor, Virginica) anhand ihrer Merkmale zu unterscheiden. Der Datensatz liegt vor in der Datei iris.csv.\n",
    "\n",
    "#### Schritte:\n",
    "1. Laden Sie den Iris-Datensatz in ein DataFrame.\n",
    "2. Trainieren Sie einen Entscheidungsbaum mit den Merkmalsdaten und den zugehörigen Klassenlabels.\n",
    "3. Testen Sie das Modell. Treffen Sie mit seiner Hilfe Vorhersagen durch einzelne Beispieldatenpunkte.\n",
    "\n",
    "*Variante:* Trainieren Sie den Entscheidungsbaum nur mit einem Teil des Iris-Datensatzes, und testen Sie das Modell dann an den übrigen Daten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module importieren\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Iris-Datensatz laden\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "print (df)\n",
    "\n",
    "# Merkmale (Features) und Zielwerte (Target) extrahieren\n",
    "X = df.drop(\"variety\", axis=1)  # Dataframe mit Merkmalen\n",
    "y = df[\"variety\"]               # Dataframe mit Zielwerten\n",
    "\n",
    "# 2. Entscheidungsbaum anlegen und trainieren\n",
    "tr = tree.DecisionTreeClassifier(min_samples_split=4)\n",
    "tr.fit(X, y)\n",
    "\n",
    "# 3. Testen mit einzelnen Beispielen\n",
    "neuePflanze1Merkmale = [[5.1, 3.5, 1.4, 0.2]]  # sollte Setosa sein (Originalwerte eines Setosa Trainingsdatums)\n",
    "neuePflanze2Merkmale = [[7.1, 3.3, 4.8, 1.5]]  # sollte Versicolor sein (um 0.1 erhöhte Originalwerte eines Versicolor Trainingsdatums)\n",
    "\n",
    "\n",
    "vorhersage1 = tr.predict(neuePflanze1Merkmale)\n",
    "vorhersage2 = tr.predict(neuePflanze2Merkmale)\n",
    "\n",
    "print(\"Vorhersage für neuePflanze1:\", vorhersage1[0])\n",
    "print(\"Vorhersage für neuePflanze2:\", vorhersage2[0])\n",
    "\n",
    "# Entscheidungsbaum visualisieren (minimal)\n",
    "tree.plot_tree(tr)\n",
    "\n",
    "# Entscheidungsbaum visualisieren (erweitert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase II - Ein tieferer Blick in den Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini-Index vs. Entropie in Entscheidungsbäumen\n",
    "\n",
    "\n",
    "Bei der Konstruktion von Entscheidungsbäumen muss entschieden werden, anhand welcher Merkmale ein Datensatz aufgeteilt wird. Ziel ist es, möglichst „reine“ Teilmengen zu erhalten – also Teilmengen, in denen möglichst nur eine Klasse vorkommt. Zwei Maße zur Bewertung dieser Reinheit sind der **Gini-Index** und die **Entropie**.\n",
    "\n",
    "#### 1. Gini-Index\n",
    "\n",
    "Der **Gini-Index** misst die Wahrscheinlichkeit, dass zwei zufällig (unabhängig) gezogene Instanzen aus dem Knoten unterschiedlichen Klassen angehören.\n",
    "\n",
    "Formel:\n",
    "\n",
    "$$\n",
    "\\text{Gini}(D) = 1 - \\sum_{i=1}^{C} p_i^2\n",
    "$$\n",
    "\n",
    "Dabei ist:\n",
    "- $D$: Aktueller Knoten bzw. Datensatz des Knotens.\n",
    "- $C$: Anzahl der Klassen\n",
    "- $p_i$: Anteil der Klasse $i$ im Datensatz des Knotens.\n",
    "\n",
    "Der Gini-Index hat:\n",
    "- Wertebereich: $[0, 1 - \\frac{1}{C}]$\n",
    "\n",
    "Geringerer Wert bedeutet höhere Reinheit. Sein Minimum ist 0, und zwar für den Fall dass alle Daten eines Datensatzes nur noch einer Klasse angehören.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 2. Entropie\n",
    "\n",
    "Die Entropie basiert auf dem Informationsgehalt einer Verteilung und misst die Unordnung (Unreinheit) eines Datensatzes.\n",
    "\n",
    "Formel:\n",
    "\n",
    "$$\n",
    "\\text{Entropie}(D) = - \\sum_{i=1}^{C} p_i \\cdot \\log_2(p_i)\n",
    "$$\n",
    "\n",
    "(Parameterbezeichnungen wie oben.)\n",
    "\n",
    "Die Entropie hat\n",
    "- Wertebereich: $[0, \\log_2 C]$\n",
    "\n",
    "Geringerer Wert bedeutet höhere Reinheit (wie beim Gini-Index). Ihr Minimum ist 0, und zwar für den Fall dass alle Daten eines Datensatzes nur noch einer Klasse angehören.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Beide Maße - Gini und Entropie - verfolgen dasselbe Ziel: optimale Trennung.\n",
    "- Gini ist rechentechnisch einfacher und führt oft zu ähnlichen Ergebnissen wie Entropie.\n",
    "- Entropie kann bei gleichverteilten Klassen feiner reagieren.\n",
    "\n",
    "Im Machine-Learning-Alltag ist die Wahl oft pragmatisch: Scikit-learn verwendet Gini standardmäßig, kann aber auch Entropie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Aufgabe - Möglichkeiten beim Training des Entscheidungsbaums\n",
    "\n",
    "- Trainieren sie den Baum aus der Schwertlilienklassifizierung basierend auf Entropie, anstatt auf Gini-Index. Beobachten Sie, ob es Unterschiede in den erstellen Bäumen gibt?\n",
    "- Experimentieren Sie auch mit anderen Konfigurationsmöglichkeiten des DecisionTreeClassifier und untersuchen Sie deren Effekte. Wofür sind Sie nützlich?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuer Anwendungsfall: Klassifizierung von Pilzen in Essbar/Giftig\n",
    "\n",
    "Bekanntermaßen sind Pilze in Deutschland nicht per se essbar – im Gegenteil: Die Grenze zwischen Delikatesse und tödlichem Irrtum kann hauchdünn sein. Seit jeher beschäftigt die Unterscheidung zwischen essbaren und giftigen Pilzen Menschen aller Kulturen, und besonders in unseren heimischen Wäldern lauern zahlreiche Doppelgänger, die selbst geübte Sammler in die Irre führen können.\n",
    "\n",
    "Im Folgenden befassen auch wir uns - im Kontext der Entscheidungsbäume - mit der Klassifikation der Pilze. \n",
    "\n",
    "\n",
    "#### Vergleich der Merkmalsbeschaffenheit: Schwertlilien vs. Pilze\n",
    "\n",
    "**-> Vergleichen Sie die Datensätze der Schwertlilienklassifikation (iris.csv) mit denen der Pilzklassifizierung (agaricus-lepiota.data). Was fällt bezüglich der Merkmale auf?**\n",
    "\n",
    "Ein Auszug aus den Daten steht auch in den folgenden zwei Tabellen:\n",
    "\n",
    "\n",
    "| Sepal Length | Sepal Width | Petal Length | Petal Width | Variety     |\n",
    "|--------------|-------------|--------------|-------------|-------------|\n",
    "| 5.1          | 3.5         | 1.4          | 0.2         | Setosa      |\n",
    "| 7.0          | 3.2         | 4.7          | 1.4         | Versicolor  |\n",
    "| 6.3          | 3.3         | 6.0          | 2.5         | Virginica   |\n",
    "\n",
    "*Tabelle 1: Merkmalsauszug – Iris-Datensatz*\n",
    "\n",
    "<br>\n",
    "\n",
    "| Class | Cap Shape | Cap Color | Odor | Gill Size |\n",
    "|-------|-----------|-----------|------|------------|\n",
    "| p     | x         | n         | p    | n          |\n",
    "| e     | x         | y         | a    | b          |\n",
    "| p     | b         | w         | l    | n          |\n",
    "\n",
    "*Tabelle 2: Merkmalsauszug – Mushroom-Datensatz*\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Aufgabe - Klassifizierung von Pilzen in Essbar/Giftig\n",
    "\n",
    "<img src=\"./PythonGrundlagen_024_Bilder/20250601_Marios_Mushroom_Dilemma.png\" alt=\"Diagramm\" width=\"550\" />\n",
    "\n",
    "Ziel ist es, ein Python-Programm zu entwickeln, das anhand der Daten in *agaricus-lepiota.data* einen Entscheidungsbaum trainiert, um Pilze in die Klassen *Essbar* und *Giftig* zu klassifizieren.\n",
    "\n",
    "#### Schritte:\n",
    "1. Informieren Sie sich darüber, wie man das Problem löst, dass der *sklearn.DecisionTreeClassifier* nicht mit Merkmalen arbeiten kann, deren Werte textuell sind.\n",
    "2. Trainieren Sie einen Entscheidungsbaum mit den Merkmalsdaten und den zugehörigen Klassenlabels.\n",
    "3. Testen Sie das Modell. Treffen Sie mit seiner Hilfe Vorhersagen durch einzelne Beispieldatenpunkte.\n",
    "4. Lassen Sie sich den Entscheidungsbaum als Graph ausgeben und unteruchen Sie seine Eigenschaften.\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Verwenden Sie weder Ihr Modell, noch das eines anderen, um tatsächlich zu entscheiden, ob Sie einen Pilz essen oder nicht! Weder die angewandten Trainingsdaten noch die besprochenen Modelle sind verifiziert!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module importieren\n",
    "\n",
    "\n",
    "#  Mushroom-Datensatz laden\n",
    "\n",
    "\n",
    "#  Entscheidungsbaum anlegen und trainieren\n",
    "\n",
    "\n",
    "#  Testen mit einzelnen Beispielen\n",
    "\n",
    "\n",
    "#  Entscheidungsbaum visualisieren\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wie gut ist mein Baum?\n",
    "\n",
    "Beim maschinellen Lernen ist es wichtig, ein Modell nicht nur auf den vorhandenen Daten zu trainieren, sondern auch seine **Verallgemeinerungsfähigkeit** zu testen.\n",
    "\n",
    "Dazu teilt man den **vorhandenen** Datensatz auf in:\n",
    "\n",
    "- **Trainingsdaten**: Diese werden verwendet, um den Entscheidungsbaum zu trainieren.\n",
    "- **Testdaten**: Diese werden genutzt, um die Qualität des trainierten Baums unabhängig zu bewerten.\n",
    "\n",
    "Eine einfache Bewertung der Qualität des trainierten Baumes ergibt sich aus der Feststellung: Wie groß ist der Anteil der korrekt vorhergesagten Testdaten?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aufgabe\n",
    "\n",
    "Wenden Sie oben beschriebene Strategie auf den Anwendungsfall der Pilzklassifizierung an: Teilen Sie die vorhandenen Daten in Trainings- und Testdaten auf. Informieren Sie sich dazu über das Modul *train_test_split* aus dem Paket *sklearn.model_selection*, und wenden Sie es in Ihrem Programm an.\n",
    "\n",
    "Um eine Bewertung der Qualität für Ihren trainierten Entscheidungsbaum zu bekommen, bietet sich das Modul *accuracy_score* aus dem Paket *sklearn.metrics* an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module importieren\n",
    "\n",
    "\n",
    "#  Daten laden\n",
    "\n",
    "\n",
    "#  Aufteilen in Trainings- und Testdaten\n",
    "\n",
    "\n",
    "#  Entscheidungsbaum trainieren\n",
    "\n",
    "\n",
    "#  Modell testen, accuracy_score ausgeben\n",
    "\n",
    "#  Visualisierung des Baums\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aufgabe\n",
    "\n",
    "Ändern Sie Ihr Programm so, dass Sie den Entscheidungsbaum mehrmals mit unterschiedlichen Zufallsaufteilungen in Trainings- und Testdaten trainieren.\n",
    "Ziel ist es, einen Baum zu finden, der eine möglichst hohe Genauigkeit (Accuracy) hat.\n",
    "\n",
    "Um Ihr Programm sinnvoll zu testen, sollte entweder der Datensatz der vorhandenen Daten verkleinert werden, oder die Größe des Baumes beschränkt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module importieren\n",
    "\n",
    "\n",
    "#  Daten laden\n",
    "\n",
    "#  Mehrere Trainings-/Testdurchläufe (z. B. 10)\n",
    "\n",
    "#   Visualisierung des Baums\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
