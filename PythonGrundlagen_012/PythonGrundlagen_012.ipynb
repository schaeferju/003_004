{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 29.01.2025 - Magic in Klassen, Erweiterte KI Textanalyse \n",
    "---\n",
    "Wir betrachten zu Beginn einen weiteren Aspekt von Klassen in Python: Die \"Magic\" Methoden. Sie ermöglichen es, das Verhalten von Objekten in vordefinierten Situationen selbst festzulegen. Danach schauen wir uns Python KI Methoden zur Textanalyse an, die über das Zählen und Gewichten von Wörtern in Texten hinausgeht. Dazu lassen wir mittels KI die Stimmung, die einem Text inneliegt, bestimmen.\n",
    "\n",
    "* Zur Bearbeitung der Aufgaben können Sie benötigte Informationen zu Python-Befehlen und zu KI relevanten Bibliotheken (numpy, scikit, pandas) aus allen verfügbaren Quellen beziehen. Die meisten findet man natürlich über eine Suche im Internet, oder durch die Nutzung von KI chat-Systemen selbst.\n",
    "Ein gutes Tutorial für den Start findet sich  z.B. hier: https://www.python-kurs.eu/numerisches_programmieren_in_Python.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase I - Magic in Klassen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiederholung Aufgabe\n",
    "Programmieren Sie eine Klasse, z.B. \"MatrixPruefer\", in der die von Ihnen geschriebenen Funktionen der oberen Aufgaben als Methoden \"gebündelt\" werden.\n",
    "\n",
    "Überlegungen:\n",
    "- Welche Attribute soll die Klasse haben?\n",
    "- Welche Aufgaben soll der Konstruktor `__int()__` der Klasse übernehmen?\n",
    "- Können die Funktionen von oben 1:1 als Methoden der Klasse kopiert werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MatrixPruefer:\n",
    "    def __init__(self, matrix):\n",
    "        \"\"\"\n",
    "        Konstruktor, der überprüft, ob die Matrix quadratisch ist.\n",
    "        \"\"\"\n",
    "        self.matrix = np.array(matrix)  # Sicherstellen, dass es ein np.array ist\n",
    "\n",
    "        zeilen, spalten = self.matrix.shape\n",
    "        if zeilen != spalten:\n",
    "            raise ValueError(\"Die Matrix muss quadratisch sein!\")\n",
    "\n",
    "        self.n = zeilen  # Hier setzen wir die Dimension der Matrix\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Anzahl der Zeilen: {self.n}\"\n",
    "\n",
    "    def diagonale_ist_eins(self):\n",
    "        \"\"\"\n",
    "        Überprüft, ob alle Elemente auf der Hauptdiagonalen den Wert 1 haben.\n",
    "        \"\"\"\n",
    "        for i in range(self.n):\n",
    "            if self.matrix[i][i] != 1:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def ist_symmetrisch(self):\n",
    "        \"\"\"\n",
    "        Überprüft, ob die gegebene quadratische Matrix symmetrisch ist.\n",
    "        \"\"\"\n",
    "        for i in range(self.n):\n",
    "            for j in range(i, self.n):  # Nur obere Dreieckshälfte prüfen\n",
    "                if self.matrix[i][j] != self.matrix[j][i]:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def werte_in_intervall_0_1(self):\n",
    "        \"\"\"\n",
    "        Überprüft, ob alle Werte in der Matrix im Bereich [0, 1] liegen.\n",
    "        \"\"\"\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                if not (0 <= self.matrix[i][j] <= 1):\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def durchschnitt_unteres_dreieck(self):\n",
    "        \"\"\"\n",
    "        Berechnet den Durchschnittswert der Elemente im unteren Dreieck der Matrix.\n",
    "        \"\"\"\n",
    "        summe = 0\n",
    "        count = 0\n",
    "        for i in range(self.n):\n",
    "            for j in range(i):\n",
    "                summe += self.matrix[i][j]\n",
    "                count += 1\n",
    "        return summe / count \n",
    "\n",
    "    def zeile_max_min_sum(self):\n",
    "        \"\"\"\n",
    "        Findet die Zeile mit der größten und kleinsten Summe der Elemente.\n",
    "        \"\"\"\n",
    "        zeilen_summen = [sum(row) for row in self.matrix]\n",
    "        max_zeile = np.argmax(zeilen_summen)\n",
    "        min_zeile = np.argmin(zeilen_summen)\n",
    "        return int(max_zeile), int(min_zeile)\n",
    "    \n",
    "\n",
    "# Hauptprogramm\n",
    "\n",
    "matrix = [\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 1]\n",
    "]\n",
    "\n",
    "matrix_pruefer1 = MatrixPruefer(matrix)\n",
    "\n",
    "# Methoden aufrufen\n",
    "print(matrix_pruefer1.diagonale_ist_eins())  \n",
    "print(matrix_pruefer1.ist_symmetrisch())     \n",
    "print(matrix_pruefer1.werte_in_intervall_0_1())  \n",
    "print(matrix_pruefer1.durchschnitt_unteres_dreieck()) \n",
    "print(matrix_pruefer1.zeile_max_min_sum())  \n",
    "\n",
    "print(matrix_pruefer1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einführung in Magic Methods in Python\n",
    "\n",
    "In Python sind **Magic Methods** (auch \"Dunder Methods\", kurz für \"Double Underscore Methods\") spezielle Methoden, die mit doppelten Unterstrichen (`__`) beginnen und enden. Sie ermöglichen es, das Verhalten von Objekten in bestimmten Situationen zu definieren, z. B. bei mathematischen Operationen, Vergleichen oder der String-Repräsentation.\n",
    "\n",
    "Magic Methods ermöglichen eine intuitive Nutzung eigener Klassen, indem sie das Verhalten von Objekten anpassen - ganz im Sinne der objektorientierten Programmierung.\n",
    "\n",
    "### Beispiele für Magic Methods\n",
    "\n",
    "1. **`__init__` (Konstruktor)**\n",
    "   - Wird beim Erstellen einer Instanz automatisch aufgerufen.\n",
    "\n",
    "2. **`__str__` (String-Repräsentation für `print()`)**\n",
    "   - Definiert die lesbare Darstellung eines Objekts.\n",
    "\n",
    "4. **Vergleichsoperatoren (`__eq__`, `__lt__`, `__gt__`, etc.)**\n",
    "   - Definieren, wie Objekte miteinander verglichen werden.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispielklasse Auto\n",
    "\n",
    "In diesem Beispiel ist der Gleichheitsoperator so definiert, dass zwei Auto-Objekte genau dann gleich sind, wenn Marke und Typ gleich sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Auto:\n",
    "    def __init__(self, marke, modell, farbe):\n",
    "        \"\"\"\n",
    "        Konstruktor zur Initialisierung der Auto-Attribute\n",
    "        \"\"\"\n",
    "        self.marke = marke\n",
    "        self.modell = modell\n",
    "        self.farbe = farbe\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"\n",
    "        Vergleicht zwei Autos. Zwei Autos gelten als gleich, wenn Marke und Modell übereinstimmen.\n",
    "        \"\"\"\n",
    "        if not isinstance(other, Auto):\n",
    "            return False\n",
    "        return self.marke == other.marke and self.modell == other.modell\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Gibt eine string-Darstellung des Autos zurück.\n",
    "        \"\"\"\n",
    "        return f\"Auto: {self.marke} {self.modell}, Farbe: {self.farbe}\"\n",
    "\n",
    "\n",
    "# Hauptprogramm:\n",
    "autoAlt = Auto(\"Citroen\", \"C1\", \"Blau\")\n",
    "autoNeu = Auto(\"Skoda\", \"Octavia\", \"Blau\")\n",
    "Leihwagen = Auto(\"Skoda\", \"Octavia\", \"Schwarz\")\n",
    "\n",
    "print(\"AutoAlt gleich AutoNeu: \", autoAlt == autoNeu)  \n",
    "print(\"AutoNeu gleich Leihwagen: \", autoNeu == Leihwagen)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Aufgabe\n",
    "\n",
    "Finden Sie heraus, wie die Vergleichsoperatoren ==, <=, <, >, >= auf Numpy-Arrays funktionieren.\n",
    "Testen Sie dazu in einem kleinen Python Programm, welche Resultate die Vergleiche bringen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Arrays definieren und vergleichen\n",
    "Array_1 = np.array([[1,2,3,4,5,6,7],[4,12,13,43,56,5,78]])\n",
    "Array_2 = np.array([1,2,3,4,5,5,7])\n",
    "\n",
    "print (Array_1 == Array_2)\n",
    "print (Array_1 <= Array_2)\n",
    "print (Array_1 >= Array_2)\n",
    "print (Array_1 < Array_2)\n",
    "print (Array_1 > Array_2)\n",
    "print (Array_1 != Array_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Aufgabe\n",
    "\n",
    "Schreiben Sie für die Klasse MatrixPruefer eine eigene Definition für den == Vergleich:\n",
    "\n",
    "Zwei MatrixPruefer-Objekte sind dann gleich, wenn, fü r jedes ihrer Matrixelemente gilt:\n",
    "\n",
    "- Ist das Matrixelement $a_{ij}$ aus dem ersten MatrixPruefer $< 0.5$, dann muss auch das entsprechende Matrixelement $b_{ij}$ aus dem zweiten Matrixpruefer $< 0.5$ sein.\n",
    "- Ist das Matrixelement $a_{ij}$ aus dem ersten MatrixPruefer $>= 0.5$, dann muss auch das entsprechende Matrixelement $b_{ij}$ aus dem zweiten Matrixpruefer $>= 0.5$ sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es die erste Ungleichheit ist an der Stelle [2][2] aufgetreten!\n",
      "False\n",
      "True\n",
      "Es die erste Ungleichheit ist an der Stelle [2][2] aufgetreten!\n",
      "False\n",
      "Die Matrizen haben nicht die gleiche Größe!\n",
      "False\n",
      "Das zweite ist kein Objekt dieser Klasse!\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Bibliotheken importieren\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Klasse MatrixPruefer\n",
    "class MatrixPruefer_Gleich:\n",
    "\n",
    "    # Konstruktor\n",
    "    def __init__(self, matrix):\n",
    "        \"\"\"\n",
    "        Konstruktor, der überprüft, ob die Matrix quadratisch ist.\n",
    "        \"\"\"\n",
    "        self.matrix = np.array(matrix)  # Sicherstellen, dass es ein np.array ist\n",
    "\n",
    "        zeilen, spalten = self.matrix.shape\n",
    "        if zeilen != spalten:\n",
    "            raise ValueError(\"Die Matrix muss quadratisch sein!\")\n",
    "\n",
    "        self.n = zeilen  # Hier setzen wir die Dimension der Matrix\n",
    "\n",
    "    # Magic Methode zum überprüfen der Gleichheit, gemäß den gegebenen Bedingungen\n",
    "    def __eq__(self, other):\n",
    "\n",
    "        #Ist das andere Überhaupt ein passendes Objekt?\n",
    "        if not isinstance(other, MatrixPruefer_Gleich):\n",
    "            print(\"Das zweite ist kein Objekt dieser Klasse!\")\n",
    "            return False\n",
    "        \n",
    "        #Keine gleiche Größe, also keine gleichen Matrizen \n",
    "        if self.n != other.n:\n",
    "            print (\"Die Matrizen haben nicht die gleiche Größe!\")\n",
    "            return False\n",
    "        \n",
    "        return np.array_equal(self.matrix < 0.5, other.matrix < 0.5)  #Python-Magic\n",
    "        \n",
    "        # #Ab hier wird endlich mal verlglichen\n",
    "        # for i in range (self.n):\n",
    "        #     for j in range(self.n):\n",
    "        #         if (self.matrix[i][j] < 0.5 and other.matrix[i][j] >= 0.5) or (self.matrix[i][j] >= 0.5 and other.matrix[i][j] < 0.5):\n",
    "        #             print(f\"Es die erste Ungleichheit ist an der Stelle [{i}][{j}] aufgetreten!\")\n",
    "        #             return False\n",
    "        # return True\n",
    "\n",
    "# Hauptprogramm\n",
    "\n",
    "matrix_1 = [\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 1]\n",
    "]\n",
    "matrix_2 = [\n",
    "    [0.6, 0.1, 0.8],\n",
    "    [0.4, 0.5, 0.2],\n",
    "    [0.7, 0.3, 0.4]\n",
    "]\n",
    "matrix_3 = [\n",
    "    [0.5, 0.4, 0.5],\n",
    "    [0.4, 0.5, 0.4],\n",
    "    [0.5, 0.4, 0.5]\n",
    "]\n",
    "\n",
    "matrix_4 = [\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 1, 0, 1],\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 1, 0, 1]\n",
    "]\n",
    "\n",
    "\n",
    "matrix_pruefer1 = MatrixPruefer_Gleich(matrix_1)\n",
    "matrix_pruefer2 = MatrixPruefer_Gleich(matrix_2)\n",
    "matrix_pruefer3 = MatrixPruefer_Gleich(matrix_3)\n",
    "matrix_pruefer4 = MatrixPruefer_Gleich(matrix_4)\n",
    "\n",
    "# Testen der Gleichheit zweier Instanzen von MatrixPruefer\n",
    "\n",
    "print (matrix_pruefer1 == matrix_pruefer2)\n",
    "print (matrix_pruefer1 == matrix_pruefer3)\n",
    "print (matrix_pruefer3 == matrix_pruefer2)\n",
    "print (matrix_pruefer1 == matrix_pruefer4)\n",
    "print (matrix_pruefer1 == matrix_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase II: Sentiment Textanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die **Sentiment-Analyse** (auch Meinungs- oder Stimmungsanalyse genannt) ist ein wichtiges Werkzeug in der **Textanalyse**. Sie dient dazu, die emotionale Haltung eines Textes automatisch zu bestimmen – ob er **positiv** oder **negativ** ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben bereits mittels **TfidfVectorizer** genutzt, um Textdaten in numerische Werte umzuwandeln, um sie für maschinelles Lernen nutzbar zu machen. Es analysiert die Häufigkeit von Wörtern in einem Text (*Term Frequency*, *TF*) und berücksichtigt, wie wichtig diese Wörter im Vergleich zu anderen Texten sind (*Inverse Document Frequency*, *IDF*).\n",
    "Die resultierenden Ähnlichkeitsvektoren für Texte wurden dann mittels Kosinus-Ähnlichkeit verglichen.\n",
    "\n",
    "Ein \"tieferer\" KI-Ansatz, um die Meinung eines oder mehrerer Texte automatisch zu bestimmen, ist die Sentiment-Analyse basierend auf dem \"BERT\"-Modell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aufgabe: Sentiment-Analyse mit einem vortrainierten BERT-Modell\n",
    "\n",
    "In dieser Aufgabe führen wir eine Sentiment-Analyse auf mehreren deutschen Texten durch, um mittels KI zu analysieren, ob die Texte eine positive oder negative Aussage haben.\n",
    "\n",
    "Installieren Sie zuerst das transformers torch Paket: \n",
    "```python\n",
    "pip install transformers torch\n",
    "```\n",
    "\n",
    "Nutze Sie in Ihrem Programm aus der `transformers` Bibliothek die `pipeline` Funktionalität. Sie bietet Zugang zu einem Modell, das auf Sentiment-Analyse spezialisiert ist.\n",
    "Informieren Sie sich, wie ein Modell für deutsche Texte genutzt werden kann.\n",
    "\n",
    "Analysieren Sie die folgenden Textbeispiele:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texts = [\n",
    "    \"Einfach einzurichten, vielseitig nutzbar, starke Leistungsübertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\",\n",
    "    \"Es gibt kaum besseres. Wenn man weiß, wie man ein WLAN-Mesh mit AVM Geräten einrichtet, der sollte hier keine Probleme haben.\",\n",
    "    \"Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Einfach einzurichten, vielseitig nutzbar, starke Leistungsübertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\n",
      "Sentiment: positive (Score: 0.9995)\n",
      "\n",
      "Text: Es gibt kaum besseres. Wenn man weiß, wie man ein WLAN-Mesh mit AVM Geräten einrichtet, der sollte hier keine Probleme haben.\n",
      "Sentiment: positive (Score: 0.9949)\n",
      "\n",
      "Text: Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\n",
      "Sentiment: negative (Score: 0.9978)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Von Bibliothek transfomerts das tool pipeline importieren\n",
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment-Analyse-Pipeline mit deutschem Modell laden\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "# Beispieltexte zur Analyse\n",
    "texts = [\n",
    "    \"Einfach einzurichten, vielseitig nutzbar, starke Leistungsübertragung, wurde mir empfohlen und kann ich absolut weiter empfehlen.\",\n",
    "    \"Es gibt kaum besseres. Wenn man weiß, wie man ein WLAN-Mesh mit AVM Geräten einrichtet, der sollte hier keine Probleme haben.\",\n",
    "    \"Ich kann dieses Produkt nicht empfehlen. Wer ein stabiles und benutzerfreundliches Mesh-System sucht, sollte sich nach Alternativen umsehen.\"\n",
    "]\n",
    "\n",
    "# Analyse der Texte\n",
    "results = sentiment_pipeline(texts)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"Text: {text}\\nSentiment: {result['label']} (Score: {result['score']:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nikitas Lösung:\n",
    "![alt text](image.png)\n",
    "In letzem Kommentar steht am Ende \"Gerät\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusammengefasst:\n",
    "\n",
    "- **NLP (Natural Language Processing)** ist der Bereich der Künstlichen Intelligenz, der sich mit der Verarbeitung von Sprache beschäftigt. Es geht darum, Computern zu ermöglichen, menschliche Sprache zu verstehen, zu interpretieren und darauf zu reagieren.\n",
    "\n",
    "- **BERT (Bidirectional Encoder Representations from Transformers)** ist ein Modell, das für verschiedene NLP-Aufgaben entwickelt wurde. Es versteht den Kontext eines Textes sowohl aus der linken als auch aus der rechten Seite eines Wortes, was zu einer besseren Textverarbeitung führt.\n",
    "\n",
    "- **Transformers** ist eine Python-Bibliothek, die es ermöglicht, BERT und viele andere vortrainierte Modelle für NLP-Aufgaben einfach zu verwenden. Die Bibliothek wurde von Hugging Face entwickelt und bietet eine Vielzahl von Tools zur Bearbeitung von Textdaten.\n",
    "\n",
    "- **Pipeline** ist eine benutzerfreundliche Schnittstelle innerhalb der Transformers-Bibliothek, die vortrainierte Modelle für eine Vielzahl von NLP-Aufgaben (wie Textklassifikation, Named Entity Recognition und Frage-Antwort-Systeme) zur Verfügung stellt. Mit wenigen Zeilen Code kann man so komplexe Aufgaben lösen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die BERT Sentiment Analyse\n",
    "\n",
    "**BERT** ,einschließlich `oliverguhr/german-sentiment-bert`, ist ein Deep Learning-Modell. Es nutzt die eine Architektur mit Selbstaufmerksamkeit, um die Beziehungen zwischen Wörtern und deren Kontext zu erfassen und zu verstehen. Das Modell wurde durch Vortraining und anschließendem Fine-Tuning auf die Sentiment-Analyse angepasst.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Funktionsweise\n",
    "\n",
    "| Punkt                                | Beschreibung                                                                                     |\n",
    "|--------------------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| **1. Vortraining**                   | Das Modell wird auf einem großen Korpus von Textdaten vortrainiert, um Sprachverständnis zu erlangen. |\n",
    "| 1.a. Masked Language Modeling (MLM) | Teilweise maskierte Wörter im Text werden vom Modell vorhergesagt, um den Kontext zu verstehen. Beispiel: \"Der Hund läuft im [MASK].\" |\n",
    "| 1.b. Next Sentence Prediction (NSP)  | Das Modell sagt voraus, ob der zweite Satz sinnvoll auf den ersten folgt. Beispiel: \"Der Hund läuft im Park.\" -> \"Er sieht viele Vögel.\" |\n",
    "| **2. Feinabstimmung**                | Das Modell wird mit gelabelten Daten (positiv, negativ) trainiert, um Sentiment-Klassen vorherzusagen. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 1. Vortraining:\n",
    "Das Modell wird zuerst auf einem riesigen Korpus von Textdaten (z. B. Wikipedia) vortrainiert, um allgemeines Sprachverständnis zu erlangen. Dabei lernt es, wie Wörter im Kontext miteinander verbunden sind, ohne dass es explizite Labels (wie Sentiment) benötigt.\n",
    "\n",
    "##### 1.a. Masked Language Modeling (MLM):\n",
    "Bei MLM wird ein Teil der Wörter im Text \"maskiert\" (also durch ein spezielles Token ersetzt, z. B. `[MASK]`), und das Modell muss vorhersagen, welches Wort an dieser Stelle steht.\n",
    "\n",
    "Beispiel:\n",
    "- **Originaltext**: \"Der Hund läuft im Park.\"\n",
    "- **Maskierter Text**: \"Der Hund läuft im [MASK].\"\n",
    "- Das Modell muss vorhersagen, dass das fehlende Wort \"Park\" ist.\n",
    "\n",
    "Diese Methode zwingt das Modell, den Kontext auf beiden Seiten eines Wortes zu verstehen, um es richtig zu erraten. So lernt das Modell, die Beziehungen zwischen den Wörtern und deren Bedeutungen zu erkennen, ohne dass es explizite Anweisungen über die Bedeutung der Wörter erhält.\n",
    "\n",
    "##### 1.b. Next Sentence Prediction (NSP):\n",
    "\n",
    "Bei NSP wird das Modell mit zwei Sätzen konfrontiert und muss vorhersagen, ob der zweite Satz inhaltlich auf den ersten folgt oder nicht.\n",
    "\n",
    "Beispiel:\n",
    "- **Satz 1**: „Der Hund läuft im Park.“\n",
    "- **Satz 2**: „Er sieht viele Vögel.“\n",
    "- Die Frage an das Modell wäre: „Folgt Satz 2 sinnvoll auf Satz 1?“ (Ja, in diesem Fall.)\n",
    "\n",
    "Dadurch lernt BERT, Beziehungen zwischen Sätzen zu erkennen und zu verstehen, wie ein Text zusammenhängend strukturiert ist.\n",
    "\n",
    "\n",
    "##### 2. Feinabstimmung:\n",
    "Danach wird das Modell auf spezifische Aufgaben wie Sentiment-Analyse angepasst. Beim Fine-Tuning wird BERT mit gelabelten Daten (positiv, negativ) trainiert, um die richtige Sentiment-Klasse für neue Texte vorherzusagen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Aufgabe: Die BERT-Sentiment-Analyse genauer kennenlernen\n",
    "\n",
    "Wenden Sie die BERT-Sentiment-Analyse aus obiger Aufgabe auf verschiedene, selbstgewählte Texte an. Beobachten Sie die Qualität der automatischen Einstufung in positiv und negativ. \n",
    "\n",
    "Mögliche Fragestellungen:\n",
    "- Ab wann kippt eine Bewertung von positiv nach negativ (oder andersherum).\n",
    "- Mischung positiver und negativer Aussagen in einem Text.\n",
    "- Versuchen Sie auch einmal, die BERT-Sentiment-Analyse \"auszutricksen\", indem Sie komplexe Sätze bilden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
